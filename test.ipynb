# Gerekli kütüphanelerin yüklenmesi
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings

# Kolaylık sağlayacak ek kütüphanelerin yüklenmesi
from dotenv import load_dotenv
load_dotenv()  # .env dosyasından API anahtarlarını yükler

import os

# Metin dosyasını okuma fonksiyonu
def read_txt(directory):
    file_loader = TextLoader(directory, encoding='utf-8')  # Dosyayı okur
    documents = file_loader.load()  # Dosyanın içeriğini belgeler olarak yükler
    return documents

# Belirtilen dosyayı oku (örneğin, "allin.txt")
doc = read_txt(r"C:\Users\emreo\ai\documents\allin.txt")

# Metni belirli boyutlarda parçalara ayırma fonksiyonu
def split_documents(documents):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # Her bir parçanın maksimum karakter sayısı
        chunk_overlap=50  # Parçalar arasında üst üste binme miktarı
    )
    split_docs = text_splitter.split_documents(documents)  # Metni parçalara böler
    return split_docs

# Metni parçala
split_docs = split_documents(doc)

# OpenAI API anahtarını çevresel değişkenlerden al
api_key = os.getenv('OPENAI_API_KEY')

# OpenAI embeddings oluşturma
embeddings = OpenAIEmbeddings(api_key=api_key)

# Bir sorgu için embedding oluşturma
vectors = embeddings.embed_query("HOW ARE YOU?")  # "HOW ARE YOU?" ifadesinin vektörünü oluşturur

# Pinecone vektör veritabanını oluşturma
from pinecone import Pinecone as PineconeClient, ServerlessSpec

# Pinecone istemcisi oluşturma
pc = PineconeClient(
    api_key=os.getenv("PINECONE_API_KEY")
)

# Pinecone'da bir indeks oluşturma veya mevcut olup olmadığını kontrol etme
index_name = "aiproject"
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=1536,  # Embedding vektör boyutu
        metric='euclidean',  # Mesafe metriği (Öklidyen)
        spec=ServerlessSpec(
            cloud='aws',
            region='us-east1'
        )
    )

# Pinecone veritabanına metinleri ekleme
from langchain_community.vectorstores import Pinecone
docsearch = Pinecone.from_texts([t.page_content for t in split_docs], embeddings, index_name=index_name)

# Vektör veritabanından benzer sonuçlar alma fonksiyonu
def retrieve_query(query, k=5):
    matching_results = docsearch.similarity_search(query, k=k)  # Sorguya en yakın k kadar sonucu döndürür
    return matching_results

# OpenAI'nin dil modelini kullanarak yanıt üretme
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import ChatOpenAI
from langchain.schema import (
    SystemMessage
)

# Chatbot için başlangıç mesajı
chat_messages = [
    SystemMessage(content='Müşterileremize yardım etmek için buradasın. Sen online yemek siparişi verilen bir sitede insanların istediği yemeği bulmasında yardımcı olan ve bu yemekleri müşterinin satın alması için pazarlayan bir yapay zekasın.İnsanlara samimi, kibar ve içten davran. insanların yemek seçme işlemlerini kolaylaştır.')
]

# OpenAI dil modelini yükle
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5)
chain = load_qa_chain(llm, chain_type="stuff")

# Sorguya yanıt verme fonksiyonu
def retrieve_answers(query):
    doc_search = retrieve_query(query)  # Sorgu ile eşleşen dokümanları al
    inputs = {
        "input_documents": doc_search,
        "question": query
    }
    response = chain.invoke(input=inputs)  # Modeli kullanarak cevap oluştur
    return response['output_text']  # Cevabı döndür

# Kullanıcı sorgusu
our_query = "diyetteyim ne yememi önerirsin"
# Sorguya karşılık gelen yanıtı al ve yazdır
answer = retrieve_answers(our_query)
print(answer)
